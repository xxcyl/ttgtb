import nest_asyncio
nest_asyncio.apply()

import google.generativeai as genai
from llama_parse import LlamaParse
from tqdm import tqdm
from collections import namedtuple
import streamlit as st
from pyngrok import ngrok
import base64
import os
import time
import re  # å¼•å…¥ re æ¨¡çµ„ç”¨æ–¼æ­£å‰‡è¡¨é”å¼è™•ç†

# è¨­å®šé è¨­åƒæ•¸
TEMPERATURE = 0.2

# å¾ç’°å¢ƒè®Šæ•¸ä¸­è®€å– API é‡‘é‘°
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
LLAMA_CLOUD_API_KEY = os.getenv('LLAMA_CLOUD_API_KEY')
genai.configure(api_key=GOOGLE_API_KEY)

# åˆå§‹åŒ– LlamaParse è§£æå™¨
parser = LlamaParse(
    api_key=LLAMA_CLOUD_API_KEY,
    result_type="markdown"
)

def summarize_with_gemini(text, instructions, model_name, temperature=TEMPERATURE):
    """ä½¿ç”¨ Gemini API ç”Ÿæˆæ‘˜è¦"""
    with tqdm(total=1, desc="Gemini API è™•ç†ä¸­") as pbar:
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(
            f"""
              {instructions}

              Article content:
              \n\n
              {text}
              """,
            generation_config=genai.types.GenerationConfig(temperature=temperature)
        )
        pbar.update(1)
              
        return response.text

# å®šç¾©å•é¡Œåˆ—è¡¨
Question = namedtuple("Question", ["number", "text"])

all_questions = [
    Question(1, "What problem does this paper aim to explore?"),
    Question(2, "Why is this problem worth investigating?"),
    Question(3, "What are the main findings and contributions of this research?"),
    Question(4, "What methods and techniques did the researchers use to conduct this study?"),
    Question(5, "What are the key theoretical foundations of this research?"),
    Question(6, "What data or samples were used in the study, and what are their characteristics?"),
    Question(7, "What is the reliability and statistical significance of the research findings?"),
    Question(8, "What challenges were encountered during the research process, and how were they overcome?"),
    Question(9, "How can the research findings be applied in practice or impact related fields?"),
    Question(10, "What are the limitations of the research, and what are the directions for future research?")
]

# ç”¨äºç»Ÿä¸€æ’ç‰ˆçš„æŒ‡ä»¤
format_instructions = """
Please ensure the following text follows a consistent Markdown format:

**Format Requirements:**
1. Each question should start with "**â“ å•é¡Œ [Number]ï¼š**", followed by the question content.
2. Each answer should start with "**ğŸ¤– å›ç­”ï¼š**", followed by the answer content.
3. After the detailed answer, provide a quote from the article. Quotes should start with "[åŸæ–‡å‡ºè™•]" and use Markdown's blockquote syntax with a single "> ".

**Example Format:**

â“ å•é¡Œ 1ï¼š What problem does this paper aim to explore?
ğŸ¤– å›ç­”ï¼š [Detailed Answer]  
> [Quote from the article]

â“ å•é¡Œ 2ï¼š Why is this problem worth investigating?
ğŸ¤– å›ç­”ï¼š [Detailed Answer]
> [Quote from the article]

**Notes:**
- Ensure the Markdown format is consistent throughout the text.
- If encountering formatting errors or other issues, please review and adjust the format accordingly.

Please reformat the text for consistency:
"""

# æœ€è¿‘çš„è¼¸å‡ºæ–‡ä»¶åˆ—è¡¨
recent_summaries = []

# åŠ è¼‰å·²ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨
def load_generated_files():
    if os.path.exists("generated_files.txt"):
        with open("generated_files.txt", "r") as f:
            return [line.strip() for line in f]
    return []

generated_files = load_generated_files()

# ä¿å­˜ç”Ÿæˆçš„æ–‡ä»¶å
def save_generated_file(filename):
    generated_files.append(filename)
    with open("generated_files.txt", "a") as f:
        f.write(f"{filename}\n")

def sanitize_filename(filename):
    """å»é™¤æ–‡ä»¶åä¸­çš„emojiå’Œæ ‡ç‚¹ç¬¦å·"""
    filename = re.sub(r'[^\w\s-]', '', filename).strip()
    filename = re.sub(r'[-\s]+', '-', filename).strip('-_')
    return filename

# Streamlit æ‡‰ç”¨ä»‹é¢
st.title("ğŸ˜´ It's time to go to bed")

# å¢åŠ èªªæ˜æ–‡å­—
st.markdown("""
### ğŸ¤µğŸ» å¤§å°å§ï¼Œæ˜¯æ™‚å€™è©²ç¡è¦ºäº†ï¼Œåˆåœ¨çœ‹è«–æ–‡å—ï¼Ÿ
""")

# --- ä¸»é é¢é¸é …å¡ ---
main_tabs = st.tabs(["åˆ†ææ–‡ç»", "æ­·å²ç´€éŒ„"]) # ç§»é™¤ "é—œæ–¼" é¸é …å¡

# --- åˆ†ææ–‡ç»é¸é …å¡ ---
with main_tabs[0]:
    st.markdown("""è«‹åœ¨å´é‚Šæ””ä¸Šå‚³ PDF æ ¼å¼çš„æ–‡ç»ï¼Œç³»çµ±å°‡è‡ªå‹•åˆ†ææ–‡ç»å…§å®¹ä¸¦ç”Ÿæˆç›¸é—œè³‡è¨Šã€‚éç¨‹éœ€è¦å¹¾åˆ†é˜ï¼Œè«‹è€å¿ƒç­‰å€™ã€‚å®Œæˆå¾Œï¼Œæ‚¨å¯ä»¥åœ¨ã€Œæ­·å²ç´€éŒ„ã€åˆ†é æ‰¾åˆ°ç”Ÿæˆçš„æ‘˜è¦ï¼ˆæœ€å¤šä¿ç•™åç­†ï¼‰ã€‚  é»æ“Šæ–‡ä»¶åå³å¯å±•é–‹æˆ–ä¸‹è¼‰æ‘˜è¦å…§å®¹ã€‚""")
    st.warning("""
    âš ï¸ **æ³¨æ„ï¼š**
    * å› ç‚º API å‘¼å«æ¬¡æ•¸æœ‰é™ï¼Œè‹¥å‡ºç¾éŒ¯èª¤è¡¨ç¤ºè¶…éä½¿ç”¨é™åˆ¶ï¼Œè«‹éå¹¾åˆ†é˜å¾Œå†è©¦ã€‚
    * AI å¯èƒ½å‡ºéŒ¯ï¼Œè«‹å‹™å¿…é–±è®€åŸæ–‡ç¢ºèªå…§å®¹ã€‚
    """)
    # **ç§»é™¤æ¨¡å‹é¸æ“‡é¸é …ï¼Œç›´æ¥ä½¿ç”¨ gemini-1.5-flash**
    model_name_option = 'gemini-1.5-flash'

    uploaded_file = st.sidebar.file_uploader("ä¸Šå‚³ PDF æ–‡ä»¶", type=["pdf"])
    if uploaded_file:
        # ç²å–ä¸Šå‚³çš„æ–‡ä»¶åç¨±
        original_filename = uploaded_file.name
        
        # ç²å–ç•¶å‰æ™‚é–“ä¸¦æ ¼å¼åŒ–
        timestamp = time.strftime("%Y%m%d_%H%M%S") 

        # å„²å­˜ä¸Šå‚³çš„æ–‡ä»¶
        with open(original_filename, "wb") as f:
            f.write(uploaded_file.getbuffer())

        # è§£æ PDF æ–‡ä»¶
        st.text("ğŸ•ºğŸ» è§£æ PDF æ–‡ä»¶ä¸­...")
        try:
            with st.spinner('è§£æ PDF æ–‡ä»¶ä¸­...'):
                documents = parser.load_data(original_filename)
                content = documents[0].get_content()
        except Exception as e:
            st.error(f"è§£æ PDF æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            st.stop()

        # åˆ†æ‰¹è©¢å•å•é¡Œä¸¦åˆä½µçµæœ
        all_answers = []
        question_groups = [all_questions[i:i + 5] for i in range(0, len(all_questions), 5)]
        total_groups = len(question_groups)
        progress_bar = st.progress(0)
        api_limit_reached = False
        for idx, question_group in enumerate(question_groups):
            if api_limit_reached:
                break
            st.text(f"ğŸ•ºğŸ» å‘¼å« Gemini API ä¸­... ï¼ˆç¬¬ {idx + 1} çµ„å•é¡Œï¼Œå…± {total_groups} çµ„ï¼‰")
            instructions = """
            Analyze the following article and answer the questions in fluent and natural-sounding Traditional Chinese that reflects common language use in Taiwan. Make sure to directly quote relevant parts from the article to support your answers. Do not translate or paraphrase the quotes.

            **Questions:**

            """
            for question in question_group:
                instructions += f"{question.number}. **{question.text}**\n"

            # ä¸ºæ¯ä¸€ç»„é—®é¢˜éƒ½åŠ å…¥è¾“å‡ºæ ¼å¼ç¤ºä¾‹
            instructions += """
            **Output Format Example:**

            ## ç ”ç©¶å•ç­”

            **1.** What problem does this paper aim to explore?
              **ğŸ¤– å›ç­”ï¼š**  
              [Detailed Answer]
              [Quote from the article]

            **2.** Why is this problem worth investigating?
              **ğŸ¤– å›ç­”ï¼š**  
              [Detailed Answer]
              [Quote from the article]
            """

            answers = summarize_with_gemini(content, instructions, model_name_option)
            
            if "API å‘¼å«æ¬¡æ•¸å·²é”ä¸Šé™" in answers:
                st.error(answers)
                api_limit_reached = True
                break
            elif "ä½¿ç”¨ Gemini API ç”Ÿæˆæ‘˜è¦æ™‚ç™¼ç”ŸéŒ¯èª¤" in answers:
                st.error(answers)
                break
            all_answers.append(answers)

            # æ›´æ–°é€²åº¦æ¢
            progress_bar.progress((idx + 1) / total_groups)

        if not api_limit_reached:
            # åˆä½µæ‰€æœ‰ç­”æ¡ˆ
            st.text("ğŸ•ºğŸ» åˆä½µæ‰€æœ‰ç­”æ¡ˆä¸­...")
            final_summary = "\n\n".join(all_answers)

            # ç»Ÿä¸€æœ€ç»ˆç­”æ¡ˆçš„æ’ç‰ˆ
            st.text("ğŸ•ºğŸ» çµ±ä¸€æ’ç‰ˆä¸­...")
            formatted_final_summary = summarize_with_gemini(final_summary, format_instructions, model_name_option, temperature=0.0)

            # å‘¼å« Gemini API åšæœ€å¾Œæ‘˜è¦
            st.text("ğŸ¤µğŸ» å‘€å‹’å‘€å‹’ï¼Œçœ‹ä¸å®Œçš„è‡­è«–æ–‡")
            instructions_refined_summary = """
            Please condense the following content, which is a Q&A format summary of a research article, into a concise abstract in fluent and natural-sounding Traditional Chinese, reflecting common language use in Taiwan. Please also include a relevant emoji at the beginning of the abstract title.

            **Output Format:**

            ## [Title]\n

            [Summary]

            **Constraints:**

            * Only use information provided in the Q&A summary.  Do not introduce any external information or knowledge.
            * The abstract should be less than 500 words.
            * Use Markdown format.
            """
            refined_summary = summarize_with_gemini(formatted_final_summary, instructions_refined_summary, model_name_option)

            # å¾ refined_summary ä¸­æå–æ¨™é¡Œä¸¦æ¸…ç†
            title = refined_summary.split('\n')[0].replace('##', '').strip()
            cleaned_title = sanitize_filename(title)

            # ä½¿ç”¨æ¸…ç†å¾Œçš„æ¨™é¡Œå’Œæ™‚é–“æˆ³ç”Ÿæˆæ–‡ä»¶å
            summary_filename = f"{timestamp}_{cleaned_title}.md"

            # ä¿å­˜æ‘˜è¦åˆ°æ‘˜è¦æ–‡ä»¶
            with open(summary_filename, "w", encoding="utf-8") as f:
                f.write(f"{refined_summary}\n\n---\n\n{formatted_final_summary}")

            # å°‡æ–‡ä»¶åç¨±å’Œå…§å®¹åŠ å…¥æœ€è¿‘çš„æ‘˜è¦åˆ—è¡¨
            recent_summaries.append((summary_filename, refined_summary, formatted_final_summary))
            save_generated_file(summary_filename)
            if len(recent_summaries) > 5:
                recent_summaries.pop(0)

            # é¡¯ç¤ºæ‘˜è¦ä¸¦æä¾›ä¸‹è¼‰é€£çµ
            st.header("æ–‡ç»åˆ†æ")
            st.markdown(f"{refined_summary}\n\n---\n\n{formatted_final_summary}")

            st.success(f"Gemini æ•´ç†å¾Œçš„é‡é»å·²ä¿å­˜åˆ°ï¼š{summary_filename}")

            # æä¾›ä¸‹è¼‰è¶…é€£çµ
            with open(summary_filename, "rb") as f:
                bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:file/markdown;base64,{b64}" download="{summary_filename}">é»æ“Šæ­¤è™•ä¸‹è¼‰æ‘˜è¦æ–‡ä»¶ ({summary_filename})</a>'
                st.markdown(href, unsafe_allow_html=True)

# --- æ­·å²ç´€éŒ„é¸é …å¡ ---
with main_tabs[1]:  # æ³¨æ„ç´¢å¼•æ›´æ”¹ç‚º 1
    st.header("æ­·å²ç´€éŒ„")

    if generated_files:
        for file in generated_files[-10:][::-1]:  # åªé¡¯ç¤ºæœ€è¿‘åç­†ï¼Œæœ€æ–°çš„åœ¨ä¸Šé¢
            with st.expander(file):
                with open(file, "r", encoding="utf-8") as f:
                    file_content = f.read()
                st.markdown(file_content)
                # æä¾›ä¸‹è¼‰é€£çµ
                with open(file, "rb") as f:
                    bytes_data = f.read()
                    b64 = base64.b64encode(bytes_data).decode()
                    href = f'<a href="data:file/markdown;base64,{b64}" download="{file}">é»æ“Šæ­¤è™•ä¸‹è¼‰æ‘˜è¦æ–‡ä»¶ ({file})</a>'
                    st.markdown(href, unsafe_allow_html=True)
    else:
        st.info("ç›®å‰æ²’æœ‰æ­·å²ç´€éŒ„ã€‚")
