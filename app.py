import nest_asyncio
nest_asyncio.apply()

import google.generativeai as genai
from llama_parse import LlamaParse
from tqdm import tqdm
from collections import namedtuple
import streamlit as st
from pyngrok import ngrok
import base64
import os
import time
import re

# è¨­å®šé è¨­åƒæ•¸
TEMPERATURE = 0.2

# å¾ç’°å¢ƒè®Šæ•¸ä¸­è®€å– API é‡‘é‘°
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
LLAMA_CLOUD_API_KEY = os.getenv('LLAMA_CLOUD_API_KEY')
genai.configure(api_key=GOOGLE_API_KEY)

# åˆå§‹åŒ– LlamaParse è§£æå™¨
parser = LlamaParse(
    api_key=LLAMA_CLOUD_API_KEY,
    result_type="markdown"
)

def summarize_with_gemini(text, instructions, model_name, temperature=TEMPERATURE):
    """ä½¿ç”¨ Gemini API ç”Ÿæˆæ‘˜è¦"""
    try:
        with tqdm(total=1, desc="Gemini API è™•ç†ä¸­") as pbar:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(
                f"""
                  {instructions}

                  Article content:
                  \n\n
                  {text}
                  """,
                generation_config=genai.types.GenerationConfig(temperature=temperature)
            )
            pbar.update(1)
            return response.text
    except Exception as e:
        return f"ä½¿ç”¨ Gemini API ç”Ÿæˆæ‘˜è¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"

# å®šç¾©å•é¡Œåˆ—è¡¨
Question = namedtuple("Question", ["number", "text"])

# å°‡å…«å€‹å•é¡Œåˆä½µæˆä¸€å€‹åˆ—è¡¨
questions = [
    Question(1, "What problem does this paper aim to explore, and why is this problem worth investigating?"),
    Question(2, "What are the main findings and contributions of this research, and what is their significance?"),
    Question(3, "What methods and techniques did the researchers use to conduct this study, and what data or samples were used?"),
    Question(4, "What is the reliability and statistical significance of the research findings?"),
    Question(5, "What are the key theoretical foundations of this research?"),
    Question(6, "What challenges were encountered during the research process, and how were they overcome?"),
    Question(7, "How can the research findings be applied in practice or impact related fields?"),
    Question(8, "What are the limitations of the research, and what are the directions for future research?")
]

# ç”¨äºç»Ÿä¸€æ’ç‰ˆçš„æŒ‡ä»¤
format_instructions = """
Please ensure the following text follows a consistent Markdown format:

**Format Requirements:**
1. Each question should start with "**â“ å•é¡Œ [Number]ï¼š**", followed by the question content.
2. Each answer should start with "**ğŸ¤– å›ç­”ï¼š**", followed by the answer content.
3. After the detailed answer, provide a quote from the article. Quotes should start with "[åŸæ–‡å‡ºè™•]" and use Markdown's blockquote syntax with a single "> ".

**Example Format:**

**â“ å•é¡Œ 1ï¼š** What problem does this paper aim to explore, and why is this problem worth investigating?
**ğŸ¤– å›ç­”ï¼š** [Detailed Answer]  
> [Quote from the article]

**â“ å•é¡Œ 2ï¼š** What are the main findings and contributions of this research, and what is their significance?
**ğŸ¤– å›ç­”ï¼š** [Detailed Answer]
> [Quote from the article]

**Notes:**
- Ensure the Markdown format is consistent throughout the text.
- If encountering formatting errors or other issues, please review and adjust the format accordingly.

Please reformat the text for consistency:
"""

# æœ€è¿‘çš„è¼¸å‡ºæ–‡ä»¶åˆ—è¡¨
recent_summaries = []

# åŠ è¼‰å·²ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨
def load_generated_files():
    if os.path.exists("generated_files.txt"):
        with open("generated_files.txt", "r") as f:
            return [line.strip() for line in f]
    return []

generated_files = load_generated_files()

# ä¿å­˜ç”Ÿæˆçš„æ–‡ä»¶å
def save_generated_file(filename):
    generated_files.append(filename)
    with open("generated_files.txt", "a") as f:
        f.write(f"{filename}\n")

def sanitize_filename(filename):
    """å»é™¤æ–‡ä»¶åä¸­çš„emojiå’Œæ ‡ç‚¹ç¬¦å·"""
    filename = re.sub(r'[^\w\s-]', '', filename).strip()
    filename = re.sub(r'[-\s]+', '-', filename).strip('-_')
    return filename

# Streamlit æ‡‰ç”¨ä»‹é¢
st.title("ğŸ˜´ It's time to go to bed")

# å¢åŠ èªªæ˜æ–‡å­—
st.markdown("""
### ğŸ¤µğŸ» å¤§å°å§ï¼Œæ˜¯æ™‚å€™è©²ç¡è¦ºäº†ï¼Œåˆåœ¨çœ‹è«–æ–‡å—ï¼Ÿ
""")

# --- ä¸»é é¢é¸é …å¡ ---
main_tabs = st.tabs(["åˆ†ææ–‡ç»", "æ­·å²ç´€éŒ„"])

# --- å´é‚Šæ¬„é¸é … ---
with st.sidebar:
    st.title("è¨­å®š")
    num_requests = st.radio("é¸æ“‡ API å‘¼å«æ¬¡æ•¸ï¼š", (1, 2), index=1, help="å¯è‡ªè¡Œå˜—è©¦æ•ˆæœå·®ç•°ã€‚")

# --- åˆ†ææ–‡ç»é¸é …å¡ ---
with main_tabs[0]:
    st.markdown("""è«‹åœ¨å´é‚Šæ””ä¸Šå‚³ PDF æ ¼å¼çš„æ–‡ç»ï¼Œç³»çµ±å°‡è‡ªå‹•åˆ†ææ–‡ç»å…§å®¹ä¸¦ç”Ÿæˆç›¸é—œè³‡è¨Šã€‚éç¨‹éœ€è¦å¹¾åˆ†é˜ï¼Œè«‹è€å¿ƒç­‰å€™ã€‚å®Œæˆå¾Œï¼Œæ‚¨å¯ä»¥åœ¨ã€Œæ­·å²ç´€éŒ„ã€åˆ†é æ‰¾åˆ°ç”Ÿæˆçš„æ‘˜è¦ï¼ˆæœ€å¤šä¿ç•™åç­†ï¼‰ã€‚  é»æ“Šæ–‡ä»¶åå³å¯å±•é–‹æˆ–ä¸‹è¼‰æ‘˜è¦å…§å®¹ã€‚""")
    st.warning("""
    âš ï¸ **æ³¨æ„ï¼š**
    * å› ç‚º API å‘¼å«æ¬¡æ•¸æœ‰é™ï¼Œè‹¥å‡ºç¾éŒ¯èª¤è¡¨ç¤ºè¶…éä½¿ç”¨é™åˆ¶ï¼Œè«‹éå¹¾åˆ†é˜å¾Œå†è©¦ã€‚
    * AI å¯èƒ½å‡ºéŒ¯ï¼Œè«‹å‹™å¿…é–±è®€åŸæ–‡ç¢ºèªå…§å®¹ã€‚
    """)
    # ç§»é™¤æ¨¡å‹é¸æ“‡é¸é …ï¼Œç›´æ¥ä½¿ç”¨ gemini-1.5-flash
    model_name_option = 'gemini-1.5-flash'

    uploaded_file = st.sidebar.file_uploader("ä¸Šå‚³ PDF æ–‡ä»¶", type=["pdf"])
    if uploaded_file:
        # ç²å–ä¸Šå‚³çš„æ–‡ä»¶åç¨±
        original_filename = uploaded_file.name
        
        # ç²å–ç•¶å‰æ™‚é–“ä¸¦æ ¼å¼åŒ–
        timestamp = time.strftime("%Y%m%d_%H%M%S")

        # å„²å­˜ä¸Šå‚³çš„æ–‡ä»¶
        with open(original_filename, "wb") as f:
            f.write(uploaded_file.getbuffer())

        # è§£æ PDF æ–‡ä»¶
        st.text("ğŸ•ºğŸ» è§£æ PDF æ–‡ä»¶ä¸­...")
        try:
            with st.spinner('è§£æ PDF æ–‡ä»¶ä¸­...'):
                documents = parser.load_data(original_filename)
                content = documents[0].get_content()
        except Exception as e:
            st.error(f"è§£æ PDF æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            st.stop()

        # æ ¹æ“šé¸æ“‡çš„ API å‘¼å«æ¬¡æ•¸èª¿æ•´å•é¡Œåˆ—è¡¨
        if num_requests == 1:
            questions_to_ask = [Question(1, " ".join([q.text for q in questions]))]
        else:
            questions_to_ask = [questions[:4], questions[4:]]

        # åˆ†æ‰¹è©¢å•å•é¡Œä¸¦åˆä½µçµæœ
        all_answers = []
        total_groups = len(questions_to_ask)
        progress_bar = st.progress(0)
        api_limit_reached = False
        for idx, question_group in enumerate(questions_to_ask):
            if api_limit_reached:
                break

            if num_requests == 1:
                st.text(f"ğŸ•ºğŸ» å‘¼å« Gemini API ä¸­...")
                instructions = """
                Analyze the following article and answer the questions in fluent and natural-sounding Traditional Chinese that reflects common language use in Taiwan. Make sure to directly quote relevant parts from the article to support your answers. Do not translate or paraphrase the quotes.

                **Questions:**

                """
                instructions += f"{question_group.number}. **{question_group.text}**\n"
                answers = summarize_with_gemini(content, instructions, model_name_option)
            else:
                st.text(f"ğŸ•ºğŸ» å‘¼å« Gemini API ä¸­... ï¼ˆç¬¬ {idx + 1} çµ„å•é¡Œï¼Œå…± {total_groups} çµ„ï¼‰")
                instructions = """
                Analyze the following article and answer the questions in fluent and natural-sounding Traditional Chinese that reflects common language use in Taiwan. Make sure to directly quote relevant parts from the article to support your answers. Do not translate or paraphrase the quotes.

                **Questions:**

                """
                for question in question_group:
                    instructions += f"{question.number}. **{question.text}**\n"

                # ä¸ºæ¯ä¸€ç»„é—®é¢˜éƒ½åŠ å…¥è¾“å‡ºæ ¼å¼ç¤ºä¾‹
                instructions += """
                **Output Format Example:**

                ## ç ”ç©¶å•ç­”

                **â“ å•é¡Œ 1ï¼š** What problem does this paper aim to explore, and why is this problem worth investigating?
                **ğŸ¤– å›ç­”ï¼š** [Detailed Answer]  
                > [Quote from the article]

                **â“ å•é¡Œ 2ï¼š** What are the main findings and contributions of this research, and what is their significance?
                **ğŸ¤– å›ç­”ï¼š** [Detailed Answer]  
                > [Quote from the article]
                """

                # å‘¼å« summarize_with_gemini å‡½æ•¸
                answers = summarize_with_gemini(content, instructions, model_name_option)

                if "è¶…éä½¿ç”¨é™åˆ¶" in answers:
                    st.warning("è¶…é API ä½¿ç”¨é™åˆ¶ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
                    api_limit_reached = True
                    break
            
            all_answers.append(answers)
            progress_bar.progress((idx + 1) / total_groups)
        
        if not api_limit_reached:
            # åˆä½µæ‰€æœ‰å›ç­”
            merged_answers = "\n\n".join(all_answers)

            # ç”Ÿæˆè¼¸å‡ºæ–‡ä»¶å
            sanitized_filename = sanitize_filename(original_filename)
            output_filename = f"output_{sanitized_filename}_{timestamp}.md"
            with open(output_filename, "w", encoding='utf-8') as f:
                f.write(merged_answers)

            # æ·»åŠ åˆ°æ­·å²è¨˜éŒ„ä¸­
            save_generated_file(output_filename)

            # é¡¯ç¤ºçµæœ
            st.success("ğŸ‰ ç”Ÿæˆæ‘˜è¦æˆåŠŸï¼")
            st.markdown("### ç”Ÿæˆçš„æ‘˜è¦")
            st.markdown(merged_answers)

            # æä¾›ä¸‹è¼‰é€£çµ
            with open(output_filename, "rb") as file:
                file_bytes = file.read()
                b64 = base64.b64encode(file_bytes).decode()
                href = f'<a href="data:text/markdown;base64,{b64}" download="{output_filename}">ä¸‹è¼‰æ‘˜è¦æ–‡ä»¶</a>'
                st.markdown(href, unsafe_allow_html=True)

# --- æ­·å²ç´€éŒ„é¸é …å¡ ---
with main_tabs[1]:
    st.markdown("""
    ## æ­·å²ç´€éŒ„

    åœ¨é€™è£¡ä½ å¯ä»¥æŸ¥çœ‹å’Œä¸‹è¼‰ä¹‹å‰ç”Ÿæˆçš„æ‘˜è¦æ–‡ä»¶ã€‚
    """)

    if generated_files:
        for filename in generated_files[-10:]:
            with open(filename, "r", encoding='utf-8') as f:
                content = f.read()
                st.markdown(f"### {filename}")
                st.markdown(content)
                with open(filename, "rb") as file:
                    file_bytes = file.read()
                    b64 = base64.b64encode(file_bytes).decode()
                    href = f'<a href="data:text/markdown;base64,{b64}" download="{filename}">ä¸‹è¼‰æ‘˜è¦æ–‡ä»¶</a>'
                    st.markdown(href, unsafe_allow_html=True)
    else:
        st.markdown("ç›®å‰æ²’æœ‰æ­·å²ç´€éŒ„ã€‚")
